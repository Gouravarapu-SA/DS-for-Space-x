# -*- coding: utf-8 -*-
"""Space_X_First_Stage_Landing_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/175MfqOTgm0r1LZIhSk-IIoe3r7JX5StT
"""

# Requests allows us to make HTTP requests which we will use to get data from an API
import requests
# Pandas is a software library written for the Python programming language for data manipulation and analysis.
import pandas as pd
# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays
import numpy as np
# Datetime is a library that allows us to represent dates
import datetime

# Setting this option will print all collumns of a dataframe
pd.set_option('display.max_columns', None)
# Setting this option will print all of the data in a feature
pd.set_option('display.max_colwidth', None)

# Takes the dataset and uses the rocket column to call the API and append the data to the list
def getBoosterVersion(data):
    for x in data['rocket']:
       if x:
        response = requests.get("https://api.spacexdata.com/v4/rockets/"+str(x)).json()
        BoosterVersion.append(response['name'])

# Takes the dataset and uses the launchpad column to call the API and append the data to the list
def getLaunchSite(data):
    for x in data['launchpad']:
       if x:
         response = requests.get("https://api.spacexdata.com/v4/launchpads/"+str(x)).json()
         Longitude.append(response['longitude'])
         Latitude.append(response['latitude'])
         LaunchSite.append(response['name'])

# Takes the dataset and uses the payloads column to call the API and append the data to the lists
def getPayloadData(data):
    for load in data['payloads']:
       if load:
        response = requests.get("https://api.spacexdata.com/v4/payloads/"+load).json()
        PayloadMass.append(response['mass_kg'])
        Orbit.append(response['orbit'])

# Takes the dataset and uses the cores column to call the API and append the data to the lists
def getCoreData(data):
    for core in data['cores']:
            if core['core'] != None:
                response = requests.get("https://api.spacexdata.com/v4/cores/"+core['core']).json()
                Block.append(response['block'])
                ReusedCount.append(response['reuse_count'])
                Serial.append(response['serial'])
            else:
                Block.append(None)
                ReusedCount.append(None)
                Serial.append(None)
            Outcome.append(str(core['landing_success'])+' '+str(core['landing_type']))
            Flights.append(core['flight'])
            GridFins.append(core['gridfins'])
            Reused.append(core['reused'])
            Legs.append(core['legs'])
            LandingPad.append(core['landpad'])

spacex_url="https://api.spacexdata.com/v4/launches/past"
response = requests.get(spacex_url)

print(response.content)

static_json_url='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/API_call_spacex_api.json'
response.status_code

if response.status_code == 200:
    data = response.json()
    df = pd.json_normalize(data)
    print(df.head())  # Display the first few rows of the DataFrame
else:
    print("Failed to retrieve data from the URL.")

df.head()

# Fetch data from the SpaceX API
spacex_url="https://api.spacexdata.com/v4/launches/past"
response = requests.get(spacex_url)

# Check if the request was successful
if response.status_code == 200:
    # Convert the JSON response to a DataFrame
    data = pd.json_normalize(response.json())
    print(data.head()) # Display the first few rows of the DataFrame
else:
    print("Failed to retrieve data from the URL.")

# Now, `data` should be a DataFrame, and you can subset it using the list of column names
data = data[['rocket', 'payloads', 'launchpad', 'cores', 'flight_number', 'date_utc']]

# We will remove rows with multiple cores because those are falcon rockets with 2 extra rocket boosters and rows that have multiple payloads in a single rocket.
data = data[data['cores'].map(len)==1]
data = data[data['payloads'].map(len)==1]

# Since payloads and cores are lists of size 1 we will also extract the single value in the list and replace the feature.
data['cores'] = data['cores'].map(lambda x : x[0])
data['payloads'] = data['payloads'].map(lambda x : x[0])

# We also want to convert the date_utc to a datetime datatype and then extracting the date leaving the time
data['date'] = pd.to_datetime(data['date_utc']).dt.date

# Using the date we will restrict the dates of the launches
data = data[data['date'] <= datetime.date(2020, 11, 13)]

#Global variables
BoosterVersion = []
PayloadMass = []
Orbit = []
LaunchSite = []
Outcome = []
Flights = []
GridFins = []
Reused = []
Legs = []
LandingPad = []
Block = []
ReusedCount = []
Serial = []
Longitude = []
Latitude = []

BoosterVersion

# Call getBoosterVersion
getBoosterVersion(data)

BoosterVersion[0:5]

# Call getLaunchSite
getLaunchSite(data)

# Call getPayloadData
getPayloadData(data)

# Call getCoreData
getCoreData(data)

launch_dict = {'FlightNumber': list(data['flight_number']),
'Date': list(data['date']),
'BoosterVersion':BoosterVersion,
'PayloadMass':PayloadMass,
'Orbit':Orbit,
'LaunchSite':LaunchSite,
'Outcome':Outcome,
'Flights':Flights,
'GridFins':GridFins,
'Reused':Reused,
'Legs':Legs,
'LandingPad':LandingPad,
'Block':Block,
'ReusedCount':ReusedCount,
'Serial':Serial,
'Longitude': Longitude,
'Latitude': Latitude}

import pandas as pd

launch_dict = {
    'FlightNumber': list(data['flight_number']),
    'Date': list(data['date']),
    'BoosterVersion': BoosterVersion,
    'PayloadMass': PayloadMass,
    'Orbit': Orbit,
    'LaunchSite': LaunchSite,
    'Outcome': Outcome,
    'Flights': Flights,
    'GridFins': GridFins,
    'Reused': Reused,
    'Legs': Legs,
    'LandingPad': LandingPad,
    'Block': Block,
    'ReusedCount': ReusedCount,
    'Serial': Serial,
    'Longitude': Longitude,
    'Latitude': Latitude
}

data = pd.DataFrame(launch_dict)

print(df.head())

data_falcon9 = data[data['BoosterVersion'] == 'Falcon 9']
data_falcon9.loc[:,'FlightNumber'] = list(range(1, data_falcon9.shape[0]+1))
data_falcon9

data_falcon9.isnull().sum()

import numpy as np

# Calculate the mean value of the PayloadMass column
mean_payload_mass = data['PayloadMass'].mean()

# Replace np.nan values with the mean value
data['PayloadMass'].replace(np.nan, mean_payload_mass, inplace=True)

missing_values = data_falcon9['LandingPad'].isnull().sum()
print("Number of missing values in the 'landingPad' column:", missing_values)

data_falcon9.to_csv('dataset_part_1.csv', index=False)

df=pd.read_csv("dataset_part_1.csv")
df.head(10)

df.isnull().sum()/len(df)*100

df.dtypes

# Calculate the number of launches on each site
launch_site_counts = df['LaunchSite'].value_counts()

# Display the counts
print(launch_site_counts)

# Calculate the number and occurrence of each orbit
orbit_counts = df['Orbit'].value_counts()

# Display the counts
print(orbit_counts)

# Calculate the number and occurrence of mission outcomes
landing_outcomes = df['Outcome'].value_counts()

# Display the counts
print(landing_outcomes)

for i,outcome in enumerate(landing_outcomes.keys()):
    print(i,outcome)

bad_outcomes=set(landing_outcomes.keys()[[1,3,5,6,7]])
bad_outcomes

# Define the set of bad outcomes
bad_outcomes = {'False Ocean', 'False RTLS', 'False ASDS', 'None ASDS', 'None None'}

# Create a new column 'landing_class' based on the 'Outcome' column
df['landing_class'] = df['Outcome'].apply(lambda x: 0 if x in bad_outcomes else 1)

# Display the first few rows of the DataFrame to see the new column
print(df.head())

df['Class'] = df['landing_class']
df[['Class']].head(8)

df.head(5)

df["Class"].mean()

launch_data = pd.DataFrame({
    'LaunchSite': [
        'CCAFS SLC 40',
        'VAFB SLC 4E',
        'CCAFS SLC 40',
        'KSC LC 39A',
        'CCAFS SLC 40'
    ]
})

launch_count = len(launch_data[launch_data['LaunchSite'] == 'CCAFS SLC 40'])
print(launch_count)

# Assuming df is your DataFrame and it includes the 'landing_class' column

# Count the total number of launches
total_launches = len(df)

# Count the number of successful launches (where landing_class is 1)
successful_launches = df[df['landing_class'] == 1].shape[0]

# Calculate the success rate
success_rate = successful_launches / total_launches

# Print the success rate
print(f"The success rate is: {success_rate * 100:.2f}%")

# Calculate the number and occurrence of each orbit
outcome_counts = df['Outcome'].value_counts()

# Display the counts
print(outcome_counts)

# Calculate the number of landing outcomes with a value of 'None'
none_count = outcome_counts['None None']

print(none_count)

df.to_csv("dataset_part_2.csv", index=False)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext sql

import csv, sqlite3

con = sqlite3.connect("my_data1.db")
cur = con.cursor()

# Commented out IPython magic to ensure Python compatibility.
# %sql sqlite:///my_data1.db

import pandas as pd
df = pd.read_csv("https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv")
df.to_sql("SPACEXTBL", con, if_exists='replace', index=False,method="multi")

# Commented out IPython magic to ensure Python compatibility.
# %sql create table SPACEXTABLE as select * from SPACEXTBL where Date is not null

cur.execute("SELECT DISTINCT \"Launch_Site\" FROM SPACEXTABLE;")
print(cur.fetchall())

cur.execute("SELECT * FROM SPACEXTABLE WHERE \"Launch_Site\" LIKE 'CCA%' LIMIT 5;")
print(cur.fetchall())

query = "SELECT SUM(PAYLOAD_MASS__KG_) AS total_payload_mass_kg FROM SPACEXTABLE WHERE Customer = 'NASA (CRS)';"
cur.execute(query)
result = cur.fetchone()
print(f"Total payload mass carried by boosters launched by NASA (CRS): {result[0]} kg")

query = "SELECT AVG(PAYLOAD_MASS__KG_) AS average_payload_mass_kg FROM SPACEXTABLE WHERE Booster_Version = 'F9 v1.1';"
cur.execute(query)
result = cur.fetchone()
print(f"Average payload mass carried by booster version F9 v1.1: {result[0]} kg")

query = "SELECT MIN(Date) FROM SPACEXTABLE WHERE Landing_Outcome = 'Success (ground pad)';"
cur.execute(query)
result = cur.fetchone()

# Printing the date of the first successful ground pad landing
print(f"Date of the first successful landing outcome in ground pad: {result[0]}")

query = "SELECT Booster_Version FROM SPACEXTABLE WHERE Mission_Outcome = 'Success' AND PAYLOAD_MASS__KG_ > 4000 AND PAYLOAD_MASS__KG_ < 6000;"
cur.execute(query)
results = cur.fetchall()
for result in results:
    print(result[0])

cur.execute("SELECT \"Mission_Outcome\", COUNT(*) FROM SPACEXTABLE GROUP BY \"Mission_Outcome\";")
print(cur.fetchall())

query = """
SELECT Booster_Version, PAYLOAD_MASS__KG_
FROM SPACEXTABLE
WHERE PAYLOAD_MASS__KG_ = (
    SELECT MAX(PAYLOAD_MASS__KG_)
    FROM SPACEXTABLE
);
"""
cur.execute(query)
results = cur.fetchall()
for result in results:
    print(f"Booster Version: {result[0]}, Payload Mass: {result[1]} kg")

query = """
SELECT
    CASE
        WHEN substr(Date, 6, 2) = '01' THEN 'January'
        WHEN substr(Date, 6, 2) = '02' THEN 'February'
        WHEN substr(Date, 6, 2) = '03' THEN 'March'
        WHEN substr(Date, 6, 2) = '04' THEN 'April'
        WHEN substr(Date, 6, 2) = '05' THEN 'May'
        WHEN substr(Date, 6, 2) = '06' THEN 'June'
        WHEN substr(Date, 6, 2) = '07' THEN 'July'
        WHEN substr(Date, 6, 2) = '08' THEN 'August'
        WHEN substr(Date, 6, 2) = '09' THEN 'September'
        WHEN substr(Date, 6, 2) = '10' THEN 'October'
        WHEN substr(Date, 6, 2) = '11' THEN 'November'
        WHEN substr(Date, 6, 2) = '12' THEN 'December'
    END AS Month,
    Booster_Version,
    Launch_Site
FROM SPACEXTABLE
WHERE substr(Date, 0, 5) = '2015' AND Landing_Outcome = 'Failure (drone ship)';
"""
cur.execute(query)
results = cur.fetchall()
for result in results:
    print(f"Month: {result[0]}, Booster Version: {result[1]}, Launch Site: {result[2]}")

query = """
SELECT Landing_Outcome, COUNT(*) AS Count
FROM SPACEXTABLE
WHERE Date BETWEEN '2010-06-04' AND '2017-03-20'
GROUP BY Landing_Outcome
ORDER BY Count DESC;
"""
cur.execute(query)
results = cur.fetchall()
for result in results:
    print(f"Landing Outcome: {result[0]}, Count: {result[1]}")

# pandas is a software library written for the Python programming language for data manipulation and analysis.
import pandas as pd
#NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays
import numpy as np
# Matplotlib is a plotting library for python and pyplot gives us a MatLab like plotting framework. We will use this in our plotter function to plot data.
import matplotlib.pyplot as plt
#Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics
import seaborn as sns

URL = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv"

df=pd.read_csv(URL)
df.head(5)

sns.catplot(y="PayloadMass", x="FlightNumber", hue="Class", data=df, aspect = 5)
plt.xlabel("Flight Number",fontsize=20)
plt.ylabel("Pay load Mass (kg)",fontsize=20)
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x='FlightNumber', y='LaunchSite', hue='Class')
plt.title('Flight Number vs. Launch Site')
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x='PayloadMass', y='LaunchSite', hue='Class')
plt.title('Payload Mass vs. Launch Site')
plt.show()

success_rate = df.groupby('Orbit')['Class'].mean()

plt.figure(figsize=(10, 6))
sns.barplot(x=success_rate.index, y=success_rate.values)
plt.title('Success Rate by Orbit Type')
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x='FlightNumber', y='Orbit', hue='Class')
plt.title('Flight Number vs. Orbit Type')
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x='PayloadMass', y='Orbit', hue='Class')
plt.title('Payload Mass vs. Orbit Type')
plt.show()

### TASK  6: Visualize the launch success yearly trend
df['Date'] = pd.to_datetime(df['Date'])
df['Year'] = df['Date'].dt.year

plt.figure(figsize=(10, 6))
sns.lineplot(data=df, x='Year', y='Class')
plt.title('Launch Success Yearly Trend')
plt.show()

# A function to Extract years from the date
# Extract the year from the 'Date' column and store it in a new column 'Year'
df['Year'] = df['Date'].dt.year

df.head()

features = df[['FlightNumber', 'PayloadMass', 'Orbit', 'LaunchSite', 'Flights', 'GridFins', 'Reused', 'Legs', 'LandingPad', 'Block', 'ReusedCount', 'Serial']]
features.head()

### TASK  7: Create dummy variables to categorical columns
# Assuming 'LaunchSite' and 'Orbit' are categorical columns
df_dummies = pd.get_dummies(df, columns=['LaunchSite', 'Orbit'])

# Assuming 'PayloadMass', 'FlightNumber', and other numeric columns exist in your DataFrame
# Assuming 'PayloadMass' and 'FlightNumber' are the only numeric columns you want to cast
numeric_columns = ['PayloadMass', 'FlightNumber']
df[numeric_columns] = df[numeric_columns].astype('float64')

import folium
import pandas as pd

# Import folium MarkerCluster plugin
from folium.plugins import MarkerCluster
# Import folium MousePosition plugin
from folium.plugins import MousePosition
# Import folium DivIcon plugin
from folium.features import DivIcon

# Download and read the `spacex_launch_geo.csv`

URL = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/spacex_launch_geo.csv'
spacex_df=pd.read_csv(URL)
spacex_df.head()

# Select relevant sub-columns: `Launch Site`, `Lat(Latitude)`, `Long(Longitude)`, `class`
spacex_df = spacex_df[['Launch Site', 'Lat', 'Long', 'class', 'Landing Outcome']]
launch_sites_df = spacex_df.groupby(['Launch Site'], as_index=False).first()
launch_sites_df = launch_sites_df[['Launch Site', 'Lat', 'Long']]
launch_sites_df

# Start location is NASA Johnson Space Center
nasa_coordinate = [29.559684888503615, -95.0830971930759]
site_map = folium.Map(location=nasa_coordinate, zoom_start=10)

# Create a blue circle at NASA Johnson Space Center's coordinate with a popup label showing its name
circle = folium.Circle(nasa_coordinate, radius=1000, color='#d35400', fill=True).add_child(folium.Popup('NASA Johnson Space Center'))
# Create a blue circle at NASA Johnson Space Center's coordinate with a icon showing its name
marker = folium.map.Marker(
    nasa_coordinate,
    # Create an icon as a text label
    icon=DivIcon(
        icon_size=(20,20),
        icon_anchor=(0,0),
        html='<div style="font-size: 12; color:#d35400;"><b>%s</b></div>' % 'NASA JSC',
        )
    )
site_map.add_child(circle)
site_map.add_child(marker)

# Iterate through each launch site in the DataFrame
for index, row in launch_sites_df.iterrows():
    # Extract the latitude and longitude for each launch site
    lat = row['Lat']
    long = row['Long']
    launch_site_name = row['Launch Site']

    # Create a folium.Circle for each launch site
    circle = folium.Circle(
        location=[lat, long],
        radius=1000, # Adjust the radius as needed
        color='#000000',
        fill=True,
        popup=launch_site_name # Add the launch site name as a popup label
    )

    # Create a folium.Marker for each launch site
    marker = folium.map.Marker(
        location=[lat, long],
        icon=DivIcon(
            icon_size=(20, 20),
            icon_anchor=(0, 0),
            html='<div style="font-size: 12; color:#d35400;"><b>%s</b></div>' % launch_site_name,
        )
    )

    # Add the circle and marker to the map
    site_map.add_child(circle)
    site_map.add_child(marker)

# Display the map
site_map

# Define colors for success and failure
success_color = '#008000' # Green for success
failure_color = '#FF0000' # Red for failure

# Iterate through each launch site in the DataFrame
for index, row in launch_sites_df.iterrows():
    # Extract the latitude and longitude for each launch site
    lat = row['Lat']
    long = row['Long']
    launch_site_name = row['Launch Site']

    # Determine the color based on the launch success rate
    # This is a simplified example. You'll need to adjust this based on your actual data
    # For example, you might have a 'Success Rate' column in your DataFrame
    if launch_site_name == 'CCAFS LC-40': # Example condition
        color = success_color
    else:
        color = failure_color

    # Create a folium.Marker for each launch site with the determined color
    marker = folium.map.Marker(
        location=[lat, long],
        icon=DivIcon(
            icon_size=(20, 20),
            icon_anchor=(0, 0),
            html='<div style="font-size: 12; color:%s;"><b>%s</b></div>' % (color, launch_site_name),
        )
    )

    # Add the marker to the map
    site_map.add_child(marker)

# Display the map
site_map

# Aggregate launch records by launch site and count the occurrences of each landing outcome
launch_outcomes = spacex_df.groupby('Launch Site')['Landing Outcome'].value_counts().unstack().fillna(0)

# Display the aggregated launch outcomes
print(launch_outcomes)

# Calculate the success rate for each launch site directly
# We'll consider a launch successful if the landing outcome is not "No attempt" or "Failure (parachute)"
# and not "Failure (drone ship)" since it's a different type of failure.
launch_outcomes['Success Rate'] = (launch_outcomes['Success (drone ship)'] + launch_outcomes['Success (ground pad)']) / launch_outcomes.sum(axis=1)

# Display the updated launch outcomes with success rates
print(launch_outcomes)

# Define a color scale for success rates
def get_color(success_rate):
    if success_rate > 0.8:
        return '#008000' # Green for high success rate
    elif success_rate > 0.5:
        return '#FFFF00' # Yellow for medium success rate
    else:
        return '#FF0000' # Red for low success rate

# Iterate through each launch site in the aggregated launch outcomes
for site, outcomes in launch_outcomes.iterrows():
    # Extract the latitude and longitude for each launch site
    lat = launch_sites_df.loc[launch_sites_df['Launch Site'] == site, 'Lat'].values[0]
    long = launch_sites_df.loc[launch_sites_df['Launch Site'] == site, 'Long'].values[0]

    # Determine the color based on the success rate
    color = get_color(outcomes['Success Rate'])

    # Create a folium.Marker for each launch site with the determined color
    marker = folium.map.Marker(
        location=[lat, long],
        icon=DivIcon(
            icon_size=(20, 20),
            icon_anchor=(0, 0),
            html='<div style="font-size: 12; color:%s;"><b>%s</b></div>' % (color, site),
        )
    )

    # Add the marker to the map
    site_map.add_child(marker)

# Display the map
site_map

import folium
from folium.plugins import MarkerCluster

# Assuming site_map is already defined and centered on the NASA Johnson Space Center

# Create a MarkerCluster object
marker_cluster = MarkerCluster().add_to(site_map)

# Function to determine marker color based on the class value
def get_marker_color(class_value):
    if class_value == 1:
        return 'green'
    else:
        return 'red'

# Iterate through each launch record in spacex_df
for index, record in spacex_df.iterrows():
    # Determine the marker color based on the class value
    marker_color = get_marker_color(record['class'])

    # Create a folium.Marker for each launch record
    marker = folium.Marker(
        location=[record['Lat'], record['Long']],
        icon=folium.Icon(color='white', icon_color=marker_color)
    )

    # Add the marker to the marker_cluster
    marker_cluster.add_child(marker)

    # Add MousePosition control to the map
    MousePosition().add_to(site_map)

# Display the map with the marker_cluster
site_map

# Add Mouse Position to get the coordinate (Lat, Long) for a mouse over on the map
formatter = "function(num) {return L.Util.formatNum(num, 5);};"
mouse_position = MousePosition(
    position='topright',
    separator=' Long: ',
    empty_string='NaN',
    lng_first=False,
    num_digits=20,
    prefix='Lat:',
    lat_formatter=formatter,
    lng_formatter=formatter,
)

site_map.add_child(mouse_position)
site_map

from math import sin, cos, sqrt, atan2, radians

def calculate_distance(lat1, lon1, lat2, lon2):
    # approximate radius of earth in km
    R = 6373.0

    lat1 = radians(lat1)
    lon1 = radians(lon1)
    lat2 = radians(lat2)
    lon2 = radians(lon2)

    dlon = lon2 - lon1
    dlat = lat2 - lat1

    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))

    distance = R * c
    return distance

from folium.plugins import MousePosition
import folium
from folium import Marker, Popup, PolyLine

# Assuming site_map is already defined and centered on the NASA Johnson Space Center
# and mouse_position is already added to the site_map

# Coordinates for the launch site (NASA Johnson Space Center)
launch_site_lat, launch_site_lon = 28.562302, -80.577356

# Coordinates for the closest coastline point you found
coastline_lat, coastline_lon = 28.56347, -80.56786

# Calculate the distance between the coastline point and the launch site
# Assuming you have a function named calculate_distance that takes four arguments:
# lat1, lon1, lat2, lon2 and returns the distance in kilometers
distance_coastline = calculate_distance(launch_site_lat, launch_site_lon, coastline_lat, coastline_lon)

# Create and add a folium.Marker on your selected closest coastline point on the map
coastline_marker = Marker(
    location=[coastline_lat, coastline_lon],
    icon=folium.Icon(color='blue', icon_color='white', icon='cloud', prefix='fa', icon_size=(20, 20)),
    popup=Popup(f"Distance to launch site: {distance_coastline:.2f} KM", max_width=200)
)
site_map.add_child(coastline_marker)

# Draw a PolyLine between a launch site to the selected coastline point
coordinates = [[launch_site_lat, launch_site_lon], [coastline_lat, coastline_lon]]
lines = PolyLine(locations=coordinates, weight=2, color='blue')
site_map.add_child(lines)

# Display the map with the marker and PolyLine
site_map

import folium
from folium.plugins import MousePosition
from folium import Marker, Popup, PolyLine
from geopy.distance import geodesic

# Coordinates for the launch site (NASA Johnson Space Center)
launch_site_lat, launch_site_lon = 28.562302, -80.577356

# Coordinates for the closest railway, highway, and city
railway_coords = (28.57111, -80.58542)
highway_coords = (28.56204, -80.58725)
city_coords = (28.3200, -80.6076)

# Function to calculate distance and draw a line between two points
def draw_line_and_marker(map, start_coords, end_coords, color, icon_type):
    distance = geodesic(start_coords, end_coords).km
    marker = Marker(
        location=end_coords,
        icon=folium.Icon(color=color, icon_color='white', icon=icon_type, prefix='fa', icon_size=(20, 20)),
        popup=Popup(f"Distance to launch site: {distance:.2f} KM", max_width=200)
    )
    map.add_child(marker)
    coordinates = [list(start_coords), list(end_coords)]
    lines = PolyLine(locations=coordinates, weight=2, color=color)
    map.add_child(lines)

# Create a map centered on the launch site
map = folium.Map(location=[launch_site_lat, launch_site_lon], zoom_start=13)

# Draw lines and markers for the closest railway, highway, and city
draw_line_and_marker(map, (launch_site_lat, launch_site_lon), railway_coords, 'red', 'train')
draw_line_and_marker(map, (launch_site_lat, launch_site_lon), highway_coords, 'blue', 'road')
draw_line_and_marker(map, (launch_site_lat, launch_site_lon), city_coords, 'green', 'building')

# Display the map
map

!pip install dash

!pip install --upgrade dash

import pandas as pd
import dash
from dash import dcc, html
from dash.dependencies import Input, Output
import plotly.express as px # Import Plotly Express

# Load the dataset
url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv'
df = pd.read_csv(url)

# Display the first few rows of the dataframe
df.head()

# Unique launch sites
launch_sites = df['LaunchSite'].unique()

# Dash app initialization
app = dash.Dash(__name__, suppress_callback_exceptions=True)

# Combine both the dropdown and the range slider into a single layout
app.layout = html.Div([
    dcc.Dropdown(
        id='launch-site-dropdown',
        options=[{'label': site, 'value': site} for site in launch_sites],
        value=launch_sites[0] # Default value is the first site
    ),
    html.Div(id='dd-output-container'),
    dcc.RangeSlider(
        id='payload-range-slider',
        min=df['PayloadMass'].min(),
        max=df['PayloadMass'].max(),
        step=1000, # Adjust step size as needed
        marks={i: '{} kg'.format(i) for i in range(int(df['PayloadMass'].min()), int(df['PayloadMass'].max()), 5000)},
        value=[df['PayloadMass'].min(), df['PayloadMass'].max()]
    ),
    html.Div(id='slider-output-container')
])

@app.callback(
    Output('dd-output-container', 'children'),
    [Input('launch-site-dropdown', 'value')]
)
def update_output(value):
    # Count the number of launches per site
    launch_counts = df['LaunchSite'].value_counts()
    # Plotly pie chart with title 'Total Launches by Site'
    fig = px.pie(values=launch_counts, names=launch_counts.index, title=f'Total Launches by Site')
    return dcc.Graph(figure=fig)

@app.callback(
    Output('slider-output-container', 'children'),
    [Input('payload-range-slider', 'value')]
)
def update_output_range(value_range):
    # Filter data based on payload range
    filtered_df = df[(df['PayloadMass'] >= value_range[0]) & (df['PayloadMass'] <= value_range[1])]
    # Plotly scatter plot with title 'Correlation between Payload and Success for All Sites'
    fig = px.scatter(filtered_df, x='PayloadMass', y='Class', color='BoosterVersion', title='Correlation between Payload and Success for All Sites')
    return dcc.Graph(figure=fig)

if __name__ == '__main__':
    app.run_server(debug=True)

# Pandas is a software library written for the Python programming language for data manipulation and analysis.
import pandas as pd
# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays
import numpy as np
# Matplotlib is a plotting library for python and pyplot gives us a MatLab like plotting framework. We will use this in our plotter function to plot data.
import matplotlib.pyplot as plt
#Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics
import seaborn as sns
# Preprocessing allows us to standarsize our data
from sklearn import preprocessing
# Allows us to split our data into training and testing data
from sklearn.model_selection import train_test_split
# Allows us to test parameters of classification algorithms and find the best one
from sklearn.model_selection import GridSearchCV
# Logistic Regression classification algorithm
from sklearn.linear_model import LogisticRegression
# Support Vector Machine classification algorithm
from sklearn.svm import SVC
# Decision Tree classification algorithm
from sklearn.tree import DecisionTreeClassifier
# K Nearest Neighbors classification algorithm
from sklearn.neighbors import KNeighborsClassifier

def plot_confusion_matrix(y,y_predict):
    "this function plots the confusion matrix"
    from sklearn.metrics import confusion_matrix

    cm = confusion_matrix(y, y_predict)
    ax= plt.subplot()
    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title('Confusion Matrix');
    ax.xaxis.set_ticklabels(['did not land', 'land']); ax.yaxis.set_ticklabels(['did not land', 'landed'])
    plt.show()

URL1 = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv"
data = pd.read_csv(URL1)
data.head()

URL2 = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_3.csv'
X = pd.read_csv(URL2)
X.head(100)

Y = data['Class'].to_numpy()

# students get this
transform = preprocessing.StandardScaler()
X = transform.fit_transform(X)

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

Y_test.shape

parameters ={'C':[0.01,0.1,1],
             'penalty':['l2'],
             'solver':['lbfgs']}

parameters = {'C':[0.01,0.1,1], 'penalty':['l2'], 'solver':['lbfgs']}
lr = LogisticRegression()
logreg_cv = GridSearchCV(lr, parameters, cv=10)
logreg_cv.fit(X_train, Y_train)

print("tuned hpyerparameters :(best parameters) ",logreg_cv.best_params_)
print("accuracy :",logreg_cv.best_score_)

print("Accuracy:", logreg_cv.score(X_test, Y_test))

yhat=logreg_cv.predict(X_test)
plot_confusion_matrix(Y_test,yhat)

parameters = {'kernel':('linear', 'rbf','poly','rbf', 'sigmoid'),
              'C': np.logspace(-3, 3, 5),
              'gamma':np.logspace(-3, 3, 5)}
svm = SVC()

svm_cv = GridSearchCV(svm, parameters, cv=10)
svm_cv.fit(X_train, Y_train)

print("tuned hpyerparameters :(best parameters) ",svm_cv.best_params_)
print("accuracy :",svm_cv.best_score_)

print("Accuracy:", svm_cv.score(X_test, Y_test))

yhat=svm_cv.predict(X_test)
plot_confusion_matrix(Y_test,yhat)

parameters = {'criterion': ['gini', 'entropy'],
     'splitter': ['best', 'random'],
     'max_depth': [2*n for n in range(1,10)],
     'max_features': ['auto', 'sqrt'],
     'min_samples_leaf': [1, 2, 4],
     'min_samples_split': [2, 5, 10]}

tree = DecisionTreeClassifier()

tree_cv = GridSearchCV(tree, parameters, cv=10)
tree_cv.fit(X_train, Y_train)

import warnings

# Ignore all warnings
warnings.filterwarnings("ignore")

print("tuned hpyerparameters :(best parameters) ",tree_cv.best_params_)
print("accuracy :",tree_cv.best_score_)

print("Accuracy:", tree_cv.score(X_test, Y_test))

yhat = tree_cv.predict(X_test)
plot_confusion_matrix(Y_test,yhat)

parameters = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],
              'p': [1,2]}

KNN = KNeighborsClassifier()

knn_cv = GridSearchCV(KNN, parameters, cv=10)
knn_cv.fit(X_train, Y_train)

print("tuned hpyerparameters :(best parameters) ",knn_cv.best_params_)
print("accuracy :",knn_cv.best_score_)

print("Accuracy:", knn_cv.score(X_test, Y_test))

yhat = knn_cv.predict(X_test)
plot_confusion_matrix(Y_test,yhat)

print("Logistic Regression Accuracy:", logreg_cv.score(X_test, Y_test))
print("Support Vector Machine Accuracy:", svm_cv.score(X_test, Y_test))
print("Decision Tree Classifier Accuracy:", tree_cv.score(X_test, Y_test))
print("K Nearest Neighbors Accuracy:", knn_cv.score(X_test, Y_test))

# Temporal Analysis: this Time serie plot will help us identify any trends or patterns in SpaceX's launch success rates.

URL1 = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv"
df = pd.read_csv(URL1)

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming 'df' is your DataFrame and it includes the 'Date' and 'Class' columns
# Convert 'Date' to datetime format if it's not already
df['Date'] = pd.to_datetime(df['Date'])

# Set 'Date' as the index
df.set_index('Date', inplace=True)

# Resample the data to get the count of successful and failed launches per month
success_counts = df[df['Class'] == 1].resample('M').size()
failed_counts = df[df['Class'] == 0].resample('M').size()

# Plot the time series
plt.figure(figsize=(12, 6))
plt.plot(success_counts, label='Successful Launches', color='green')
plt.plot(failed_counts, label='Failed Launches', color='red')
plt.title('SpaceX Launch Success Rates Over Time')
plt.xlabel('Date')
plt.ylabel('Number of Launches')
plt.legend()
plt.show()

#Geospatial Analysis: For geospatial analysis, we'll use the geopandas library to perform spatial clustering on the launch sites.
#This example assumes you have a dataset with launch site coordinates.

import matplotlib.pyplot as plt

# Assuming logreg_cv, svm_cv, tree_cv, and knn_cv are the GridSearchCV objects for each model
models = ['Logistic Regression', 'Support Vector Machine', 'Decision Tree', 'K Nearest Neighbors']
accuracies = [
    logreg_cv.score(X_test, Y_test),
    svm_cv.score(X_test, Y_test),
    tree_cv.score(X_test, Y_test),
    knn_cv.score(X_test, Y_test)
]

plt.bar(models, accuracies)
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Classification Model Accuracy Comparison')
plt.show()

# Find the index of the best accuracy
best_index = accuracies.index(max(accuracies))

# Use the index to get the best model and its accuracy
best_model = models[best_index]
best_accuracy = accuracies[best_index]

print(f"The best performing model is {best_model} with an accuracy of {best_accuracy}")

# Assuming best_model is the name of the best performing model
if best_model == 'Logistic Regression':
    yhat = logreg_cv.predict(X_test)
elif best_model == 'Support Vector Machine':
    yhat = svm_cv.predict(X_test)
elif best_model == 'Decision Tree':
    yhat = tree_cv.predict(X_test)
elif best_model == 'K Nearest Neighbors':
    yhat = knn_cv.predict(X_test)

plot_confusion_matrix(Y_test, yhat)

!pip install geopandas

import geopandas as gpd
from sklearn.cluster import DBSCAN
from shapely.geometry import Point

URL = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/spacex_launch_geo.csv'
df=pd.read_csv(URL)
# Assuming 'df' is your DataFrame and it includes 'Lat' and 'Long' columns for coordinates
# Create a GeoDataFrame
geometry = [Point(xy) for xy in zip(df['Long'], df['Lat'])]
gdf = gpd.GeoDataFrame(df, geometry=geometry)

# Perform DBSCAN clustering
clustering = DBSCAN(eps=0.5, min_samples=5).fit(gdf[['Long', 'Lat']])
gdf['cluster'] = clustering.labels_

# Plot the clusters
fig, ax = plt.subplots(figsize=(10, 10))
gdf.plot(column='cluster', ax=ax, legend=True)
plt.title('Spatial Clustering of Launch Sites')
plt.show()